<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="Lulin">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

    
    <!--- Seo Part-->
    
    <link rel="canonical" href="http://example.com/2023/12/04/clip-android/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
        <meta name="description" content="CLIP 模型在 Android 端的应用0. ONNXRuntime  ONNX Runtime 是一个跨平台的推理和训练机器学习框架。支持 Pytorch、TensorFlow、Keras 等框架模型，同时支持在多种平台使用。   1. Google MLKit Translation API这是由谷歌提供的移动端机器学习套件，同时支持 Android 和 iOS，支持 50 多种语言。MLK">
<meta property="og:type" content="article">
<meta property="og:title" content="CLIP模型在Android端的应用">
<meta property="og:url" content="http://example.com/2023/12/04/clip-android/index.html">
<meta property="og:site_name" content="Lulin">
<meta property="og:description" content="CLIP 模型在 Android 端的应用0. ONNXRuntime  ONNX Runtime 是一个跨平台的推理和训练机器学习框架。支持 Pytorch、TensorFlow、Keras 等框架模型，同时支持在多种平台使用。   1. Google MLKit Translation API这是由谷歌提供的移动端机器学习套件，同时支持 Android 和 iOS，支持 50 多种语言。MLK">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2023/12/04/clip-android/onnx.png">
<meta property="og:image" content="http://example.com/2023/12/04/clip-android/onnx-platform.png">
<meta property="article:published_time" content="2023-12-04T15:06:20.000Z">
<meta property="article:modified_time" content="2024-05-13T03:49:29.840Z">
<meta property="article:author" content="LeeLulin">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/12/04/clip-android/onnx.png">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/favicon.ico" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico">
    <meta name="theme-color" content="#2979ff">
    <link rel="shortcut icon" href="/images/favicon.ico">
    <!--- Page Info-->
    
    <title>
        
            CLIP模型在Android端的应用 -
        
        Lulin
    </title>
    
<link rel="stylesheet" href="/css/style.css">


    
        
<link rel="stylesheet" href="/assets/build/styles.css">

    

    
<link rel="stylesheet" href="/fonts/fonts.css">

    
<link rel="stylesheet" href="/fonts/Satoshi/satoshi.css">

    
<link rel="stylesheet" href="/fonts/Chillax/chillax.css">

    <!--- Font Part-->
    
    
    
    

    <!--- Inject Part-->
    
    <script id="hexo-configurations">
    window.config = {"hostname":"example.com","root":"/","language":"en"};
    window.theme = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"14px","image_alignment":"center","image_caption":false,"link_icon":true},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":true,"auto":false,"list":[]},"code_block":{"copy":true,"style":"mac","font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":3,"number":false,"expand":true,"init_open":true},"copyright":true,"lazyload":true,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"mobile_limit":2,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#2979ff","secondary":null},"global":{"fonts":{"chinese":{"enable":false,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null}},"content_max_width":"1000px","sidebar_width":"210px","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":false,"percentage":true},"website_counter":{"url":"https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js","enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"single_page":true,"open_graph":true,"google_analytics":{"enable":false,"id":null}},"home_banner":{"enable":true,"style":"fixed","image":{"light":"/images/home-light.jpg","dark":"/images/home-dark.jpg"},"title":"Lulin","subtitle":{"text":["此时，此地，此身"],"hitokoto":{"enable":true,"api":"https://v1.hitokoto.cn"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":false,"smart_backspace":true},"text_color":{"light":"#fff","dark":"#d1d1b6"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":true,"links":{"github":"https://github.com/LeeLulin","instagram":null,"zhihu":null,"twitter":null,"email":"471178167@qq.com"},"qrs":{"weixin":null}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null}]},"mermaid":{"enable":false,"version":"9.3.0"}},"version":"2.5.0","navbar":{"auto_hide":false,"color":{"left":"#f78736","right":"#367df7","transparency":35},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Tags":{"icon":"fa-regular fa-tags","path":"/tags"},"Her":{"path":"/mygirl","icon":"fa-regular fa-venus"},"About":{"icon":"fa-regular fa-user","submenus":{"Me":"/about","Github":"https://github.com/LeeLulin","Blog":"https://blog.leelulin.xyz"}}},"search":{"enable":true,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"blur"},"home":{"sidebar":{"enable":true,"position":"left","first_item":"menu","announcement":null,"links":null},"article_date_format":"auto","categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}},"footerStart":"2020/3/12 15:39:34"};
    window.lang_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
    window.data = {"masonry":false};
  </script>
    
    <!--- Fontawesome Part-->
    
<link rel="stylesheet" href="/fontawesome/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/brands.min.css">

    
<link rel="stylesheet" href="/fontawesome/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/regular.min.css">

    
    
    
    
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="progress-bar-container">
    

    
        <span class="pjax-progress-bar"></span>
        <span class="swup-progress-icon">
            <i class="fa-solid fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container" id="swup">

    

    <div class="main-content-container">


        <div class="main-content-header">
            <header class="navbar-container">
    
    <div class="navbar-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                
                Lulin
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/"  >
                                    
                                        
                                            <i class="fa-regular fa-house"></i>
                                        
                                        HOME
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/archives"  >
                                    
                                        
                                            <i class="fa-regular fa-archive"></i>
                                        
                                        ARCHIVES
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/tags"  >
                                    
                                        
                                            <i class="fa-regular fa-tags"></i>
                                        
                                        TAGS
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/mygirl"  >
                                    
                                        
                                            <i class="fa-regular fa-venus"></i>
                                        
                                        HER
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="has-dropdown" 
                                    href="#" onClick="return false;">
                                    
                                        
                                            <i class="fa-regular fa-user"></i>
                                        
                                        ABOUT&nbsp;<i class="fa-solid fa-chevron-down"></i>
                                    
                                </a>
                                <!-- Submenu -->
                                
                                    <ul class="sub-menu">
                                    
                                        <li>
                                        <a href="/about">ME
                                        </a>
                                        </li>
                                    
                                        <li>
                                        <a target="_blank" rel="noopener" href="https://github.com/LeeLulin">GITHUB
                                        </a>
                                        </li>
                                    
                                        <li>
                                        <a target="_blank" rel="noopener" href="https://blog.leelulin.xyz">BLOG
                                        </a>
                                        </li>
                                    
                                    </ul>
                                
                            </li>
                    
                    
                        <li class="navbar-item search search-popup-trigger">
                            <i class="fa-solid fa-magnifying-glass"></i>
                        </li>
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fa-solid fa-magnifying-glass"></i></div>
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile drawer -->
    <div class="navbar-drawer w-full absolute top-0 left-0 bg-background-color">
        <ul class="drawer-navbar-list flex flex-col justify-start items-center">
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group " 
                        href="/"  >
                             
                                
                                    <i class="fa-regular fa-house"></i>
                                
                                HOME
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group " 
                        href="/archives"  >
                             
                                
                                    <i class="fa-regular fa-archive"></i>
                                
                                ARCHIVES
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group " 
                        href="/tags"  >
                             
                                
                                    <i class="fa-regular fa-tags"></i>
                                
                                TAGS
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group " 
                        href="/mygirl"  >
                             
                                
                                    <i class="fa-regular fa-venus"></i>
                                
                                HER
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group has-dropdown" 
                        href="#" onClick="return false;">
                            
                                
                                    <i class="fa-regular fa-user"></i>
                                
                                ABOUT&nbsp;<i class="group-hover:rotate-180 transition-transform fa-solid fa-chevron-down"></i>
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                              
                        
                            <li class="drawer-navbar-item text-base flex justify-center items-center hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                <a class="py-0.5" href="/about">ME</a>
                            </li>
                        
                            <li class="drawer-navbar-item text-base flex justify-center items-center hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                <a class="py-0.5" target="_blank" rel="noopener" href="https://github.com/LeeLulin">GITHUB</a>
                            </li>
                        
                            <li class="drawer-navbar-item text-base flex justify-center items-center hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                <a class="py-0.5" target="_blank" rel="noopener" href="https://blog.leelulin.xyz">BLOG</a>
                            </li>
                        
                    
            

        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="main-content-body">

            

            <div class="main-content">

                
                    <div class="post-page-container">
    <div class="article-content-container">

        <div class="article-title">
            
                <h1 class="article-title-regular">CLIP模型在Android端的应用</h1>
            
            </div>
            
                    
        
        
            <div class="article-header flex flex-row gap-2 items-center">
                <div class="avatar w-[46px] h-[46px] flex-shrink-0 rounded-medium border border-border-color p-[1px]">
                    <img src="/about/index/user.png">
                </div>
                <div class="info flex flex-col justify-between">
                    <div class="author flex items-center">
                        <span class="name text-default-text-color text-lg font-semibold">Lulin</span>
                        
                            <span class="author-label ml-1.5 text-xs px-2 py-0.5 rounded-small text-third-text-color border border-shadow-color-1">Lv2</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2023-12-04 15:06:20</span>
        <span class="mobile">2023-12-04 15:06:20</span>
        <span class="hover-info">Created</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2024-05-13 03:49:29</span>
            <span class="mobile">2024-05-13 03:49:29</span>
            <span class="hover-info">Updated</span>
        </span>
    

    
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fa-regular fa-typewriter"></i>&nbsp;<span>1.1k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fa-regular fa-clock"></i>&nbsp;<span>6 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        


        <div class="article-content markdown-body">
            <h1 id="CLIP-模型在-Android-端的应用"><a href="#CLIP-模型在-Android-端的应用" class="headerlink" title="CLIP 模型在 Android 端的应用"></a>CLIP 模型在 Android 端的应用</h1><h2 id="0-ONNXRuntime"><a href="#0-ONNXRuntime" class="headerlink" title="0. ONNXRuntime"></a>0. ONNXRuntime</h2><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/12/04/clip-android/onnx.png"
                      class="" title="onnx"
                >

<p>ONNX Runtime 是一个跨平台的推理和训练机器学习框架。支持 Pytorch、TensorFlow、Keras 等框架模型，同时支持在多种平台使用。</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/12/04/clip-android/onnx-platform.png"
                      class="" title="platform"
                >

<h2 id="1-Google-MLKit-Translation-API"><a href="#1-Google-MLKit-Translation-API" class="headerlink" title="1. Google MLKit Translation API"></a>1. Google MLKit Translation API</h2><p>这是由谷歌提供的移动端机器学习套件，同时支持 Android 和 iOS，支持 50 多种语言。MLKit 提供在线翻译模型，也可以离线集成到 APP 中。</p>
<div class="highlight-container" data-rel="Kotlin"><figure class="iseeu highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dependencies &#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">  implementation <span class="string">&#x27;com.google.mlkit:translate:17.0.2&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="Kotlin"><figure class="iseeu highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">englishChineseTranslator.translate(text)</span><br><span class="line">    .addOnSuccessListener &#123; translatedText -&gt;</span><br><span class="line">        <span class="comment">// Translation successful.</span></span><br><span class="line">    &#125;</span><br><span class="line">    .addOnFailureListener &#123; exception -&gt;</span><br><span class="line">         <span class="comment">// Error.</span></span><br><span class="line">         <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></div>

<h2 id="3-Pytorch-转-ONNX"><a href="#3-Pytorch-转-ONNX" class="headerlink" title="3. Pytorch 转 ONNX"></a>3. Pytorch 转 ONNX</h2><p>转换 Text 模型</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> clip</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> Tensor</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># Export ImageEncoder of the CLIP to onnx model</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    device = <span class="string">&quot;cpu&quot;</span></span><br><span class="line">    <span class="comment"># print(clip.available_models())</span></span><br><span class="line">    model, preprocess = clip.load(<span class="string">&quot;ViT-B/32&quot;</span>, device=device, jit=<span class="literal">False</span>)</span><br><span class="line">    i = Image.<span class="built_in">open</span>(<span class="string">&quot;../../image.jpg&quot;</span>)</span><br><span class="line">    input_tensor: Tensor = preprocess(i).unsqueeze(<span class="number">0</span>).to(device)</span><br><span class="line">    vit = model.visual</span><br><span class="line">    vit.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    onnx_filename = <span class="string">&#x27;clip-image-encoder.onnx&#x27;</span></span><br><span class="line">    torch.onnx.export(vit, input_tensor, onnx_filename)</span><br><span class="line">    <span class="comment"># python -m onnxsim clip-image-encoder.onnx clip-image-encoder-optimized.onnx</span></span><br></pre></td></tr></table></figure></div>

<p>转换 Image 模型</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> clip</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResidualAttentionBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model: <span class="built_in">int</span>, n_head: <span class="built_in">int</span>, attn_mask: torch.Tensor = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.attn = nn.MultiheadAttention(d_model, n_head)</span><br><span class="line">        self.ln_1 = LayerNorm(d_model)</span><br><span class="line">        self.mlp = nn.Sequential(OrderedDict([</span><br><span class="line">            (<span class="string">&quot;c_fc&quot;</span>, nn.Linear(d_model, d_model * <span class="number">4</span>)),</span><br><span class="line">            (<span class="string">&quot;gelu&quot;</span>, QuickGELU()),</span><br><span class="line">            (<span class="string">&quot;c_proj&quot;</span>, nn.Linear(d_model * <span class="number">4</span>, d_model))</span><br><span class="line">        ]))</span><br><span class="line">        self.ln_2 = LayerNorm(d_model)</span><br><span class="line">        self.attn_mask = attn_mask</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">attention</span>(<span class="params">self, x: torch.Tensor</span>):</span><br><span class="line">        self.attn_mask = self.attn_mask.to(dtype=x.dtype, device=x.device) <span class="keyword">if</span> self.attn_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> self.attn(x, x, x, need_weights=<span class="literal">False</span>, attn_mask=self.attn_mask)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span><br><span class="line">        x = x + self.attention(self.ln_1(x))</span><br><span class="line">        x = x + self.mlp(self.ln_2(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Transformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, width: <span class="built_in">int</span>, layers: <span class="built_in">int</span>, heads: <span class="built_in">int</span>, attn_mask: torch.Tensor = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.width = width</span><br><span class="line">        self.layers = layers</span><br><span class="line">        self.resblocks = nn.Sequential(*[ResidualAttentionBlock(width, heads, attn_mask) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(layers)])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span><br><span class="line">        <span class="keyword">return</span> self.resblocks(x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LayerNorm</span>(nn.LayerNorm):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Subclass torch&#x27;s LayerNorm to handle fp16.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span><br><span class="line">        orig_type = x.dtype</span><br><span class="line">        ret = <span class="built_in">super</span>().forward(x.<span class="built_in">type</span>(torch.float32))</span><br><span class="line">        <span class="keyword">return</span> ret.<span class="built_in">type</span>(orig_type)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QuickGELU</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>):</span><br><span class="line">        <span class="keyword">return</span> x * torch.sigmoid(<span class="number">1.702</span> * x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TextEncoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">          embed_dim: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">          <span class="comment"># text</span></span></span><br><span class="line"><span class="params">          context_length: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">          vocab_size: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">          transformer_width: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">          transformer_heads: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">          transformer_layers: <span class="built_in">int</span></span></span><br><span class="line"><span class="params">          </span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.context_length = context_length</span><br><span class="line"></span><br><span class="line">        self.transformer = Transformer(</span><br><span class="line">            width=transformer_width,</span><br><span class="line">            layers=transformer_layers,</span><br><span class="line">            heads=transformer_heads,</span><br><span class="line">            attn_mask=self.build_attention_mask()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.vocab_size = vocab_size</span><br><span class="line">        self.token_embedding = nn.Embedding(vocab_size, transformer_width)</span><br><span class="line">        self.positional_embedding = nn.Parameter(torch.empty(self.context_length, transformer_width))</span><br><span class="line">        self.ln_final = LayerNorm(transformer_width)</span><br><span class="line"></span><br><span class="line">        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(<span class="number">1</span> / <span class="number">0.07</span>))</span><br><span class="line">        self.temperature = nn.Parameter(torch.tensor(<span class="number">0.07</span>))</span><br><span class="line"></span><br><span class="line">        self.text_projection = nn.Parameter(torch.empty(transformer_width, embed_dim))</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;text_projection shape: <span class="subst">&#123;self.text_projection.shape&#125;</span>&quot;</span>)</span><br><span class="line">        self.dtype = torch.float32</span><br><span class="line"></span><br><span class="line">        self.initialize_parameters()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">initialize_parameters</span>(<span class="params">self</span>):</span><br><span class="line">        nn.init.normal_(self.token_embedding.weight, std=<span class="number">0.02</span>)</span><br><span class="line">        nn.init.normal_(self.positional_embedding, std=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">        proj_std = (self.transformer.width ** -<span class="number">0.5</span>) * ((<span class="number">2</span> * self.transformer.layers) ** -<span class="number">0.5</span>)</span><br><span class="line">        attn_std = self.transformer.width ** -<span class="number">0.5</span></span><br><span class="line">        fc_std = (<span class="number">2</span> * self.transformer.width) ** -<span class="number">0.5</span></span><br><span class="line">        <span class="keyword">for</span> block <span class="keyword">in</span> self.transformer.resblocks:</span><br><span class="line">            nn.init.normal_(block.attn.in_proj_weight, std=attn_std)</span><br><span class="line">            nn.init.normal_(block.attn.out_proj.weight, std=proj_std)</span><br><span class="line">            nn.init.normal_(block.mlp.c_fc.weight, std=fc_std)</span><br><span class="line">            nn.init.normal_(block.mlp.c_proj.weight, std=proj_std)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.text_projection <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.normal_(self.text_projection, std=self.transformer.width ** -<span class="number">0.5</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            nn.init.normal_(self.text_projection, std=self.custom_text_config[<span class="string">&#x27;text_rep_size&#x27;</span>] ** -<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build_attention_mask</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># lazily create causal attention mask, with full attention between the vision tokens</span></span><br><span class="line">        <span class="comment"># pytorch uses additive attention mask; fill with -inf</span></span><br><span class="line">        mask = torch.empty(self.context_length, self.context_length)</span><br><span class="line">        mask.fill_(<span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>))</span><br><span class="line">        mask.triu_(<span class="number">1</span>)  <span class="comment"># zero out the lower diagonal</span></span><br><span class="line">        <span class="keyword">return</span> mask</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, text</span>):</span><br><span class="line">        <span class="comment"># print(f&#x27;text: &#123;text&#125;&#x27;)</span></span><br><span class="line">        x = self.token_embedding(text).<span class="built_in">type</span>(self.dtype)  <span class="comment"># [batch_size, n_ctx, d_model]</span></span><br><span class="line"></span><br><span class="line">        x = x + self.positional_embedding.<span class="built_in">type</span>(self.dtype)</span><br><span class="line">        x = x.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)  <span class="comment"># NLD -&gt; LND</span></span><br><span class="line">        x = self.transformer(x)</span><br><span class="line">        x = x.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)  <span class="comment"># LND -&gt; NLD</span></span><br><span class="line">        x = self.ln_final(x).<span class="built_in">type</span>(self.dtype)</span><br><span class="line">        <span class="comment"># x.shape = [batch_size, n_ctx, transformer.width]</span></span><br><span class="line">        <span class="comment"># take features from the eot embedding (eot_token is the highest number in each sequence)</span></span><br><span class="line">        x = x[torch.arange(x.shape[<span class="number">0</span>]), text.argmax(dim=-<span class="number">1</span>)] @ self.text_projection</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># Export ImageEncoder of the CLIP to onnx model</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">import</span> clip</span><br><span class="line"></span><br><span class="line">    device = <span class="string">&quot;cpu&quot;</span></span><br><span class="line">    model, preprocess = clip.load(<span class="string">&quot;ViT-B/32&quot;</span>, device=device)</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    text_encoder = TextEncoder(embed_dim=<span class="number">512</span>, context_length=<span class="number">77</span>, vocab_size=<span class="number">49408</span>,</span><br><span class="line">                               transformer_width=<span class="number">512</span>, transformer_heads=<span class="number">8</span>, transformer_layers=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">    missing_keys, unexpected_keys = text_encoder.load_state_dict(model.state_dict(), strict=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    text_encoder.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    input_tensor = clip.tokenize(<span class="string">&quot;a diagram&quot;</span>).to(device)</span><br><span class="line">    traced_model = torch.jit.trace(text_encoder, input_tensor)</span><br><span class="line"></span><br><span class="line">    onnx_filename = <span class="string">&#x27;clip-text-encoder.onnx&#x27;</span></span><br><span class="line"></span><br><span class="line">    torch.onnx.export(text_encoder, input_tensor, onnx_filename)</span><br><span class="line">    <span class="comment"># python -m onnxsim clip-text-encoder.onnx clip-text-encoder-optimized.onnx</span></span><br></pre></td></tr></table></figure></div>

<h2 id="4-Android-调用-ONNX"><a href="#4-Android-调用-ONNX" class="headerlink" title="4. Android 调用 ONNX"></a>4. Android 调用 ONNX</h2><p>ImageEncoder</p>
<div class="highlight-container" data-rel="Kotlin"><figure class="iseeu highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">suspend</span> <span class="function"><span class="keyword">fun</span> <span class="title">encode</span><span class="params">(bitmap: <span class="type">Bitmap</span>)</span></span> = withContext&lt;FloatBuffer&gt;(Dispatchers.Default) &#123;</span><br><span class="line">        <span class="keyword">val</span> ortEnv = OrtEnvironment.getEnvironment()</span><br><span class="line">        <span class="keyword">if</span> (ortSession == <span class="literal">null</span>) &#123;</span><br><span class="line">            ortSession = ortEnv.createSession(</span><br><span class="line">                AssetUtil.assetFilePath(SeekingApplication.context, modelPath),</span><br><span class="line">                options</span><br><span class="line">            )</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> imageBitmap = preprocess(bitmap)</span><br><span class="line">        <span class="keyword">val</span> floatBuffer = allocateFloatBuffer(floatBufferElementCount)</span><br><span class="line">        floatBuffer.rewind()</span><br><span class="line">        bitmapToFloatBuffer(</span><br><span class="line">            imageBitmap,</span><br><span class="line">            <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">            <span class="number">224</span>, <span class="number">224</span>,</span><br><span class="line">            normMeanRGB,</span><br><span class="line">            normStdRGB,</span><br><span class="line">            floatBuffer,</span><br><span class="line">            <span class="number">0</span>,</span><br><span class="line">            MemoryFormat.CONTIGUOUS,</span><br><span class="line">        )</span><br><span class="line">        floatBuffer.rewind()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> inputName = ortSession?.inputNames?.iterator()?.next()</span><br><span class="line">        <span class="keyword">val</span> shape: LongArray = longArrayOf(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">        ortEnv.use &#123; env -&gt;</span><br><span class="line">            <span class="keyword">val</span> tensor = OnnxTensor.createTensor(env, floatBuffer, shape)</span><br><span class="line">            <span class="keyword">val</span> output: OrtSession.Result? =</span><br><span class="line">                ortSession?.run(Collections.singletonMap(inputName, tensor))</span><br><span class="line">            <span class="keyword">val</span> resultBuffer = output?.<span class="keyword">get</span>(<span class="number">0</span>) <span class="keyword">as</span> OnnxTensor</span><br><span class="line">            <span class="keyword">return</span><span class="symbol">@withContext</span> (resultBuffer.floatBuffer)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></div>

<p>TextEncoder</p>
<div class="highlight-container" data-rel="Kotlin"><figure class="iseeu highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">suspend</span> <span class="function"><span class="keyword">fun</span> <span class="title">encode</span><span class="params">(bitmap: <span class="type">Bitmap</span>)</span></span> = withContext&lt;FloatBuffer&gt;(Dispatchers.Default) &#123;</span><br><span class="line">        <span class="keyword">val</span> ortEnv = OrtEnvironment.getEnvironment()</span><br><span class="line">        <span class="keyword">if</span> (ortSession == <span class="literal">null</span>) &#123;</span><br><span class="line">            ortSession = ortEnv.createSession(</span><br><span class="line">                AssetUtil.assetFilePath(SeekingApplication.context, modelPath),</span><br><span class="line">                options</span><br><span class="line">            )</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> imageBitmap = preprocess(bitmap)</span><br><span class="line">        <span class="keyword">val</span> floatBuffer = allocateFloatBuffer(floatBufferElementCount)</span><br><span class="line">        floatBuffer.rewind()</span><br><span class="line">        bitmapToFloatBuffer(</span><br><span class="line">            imageBitmap,</span><br><span class="line">            <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">            <span class="number">224</span>, <span class="number">224</span>,</span><br><span class="line">            normMeanRGB,</span><br><span class="line">            normStdRGB,</span><br><span class="line">            floatBuffer,</span><br><span class="line">            <span class="number">0</span>,</span><br><span class="line">            MemoryFormat.CONTIGUOUS,</span><br><span class="line">        )</span><br><span class="line">        floatBuffer.rewind()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> inputName = ortSession?.inputNames?.iterator()?.next()</span><br><span class="line">        <span class="keyword">val</span> shape: LongArray = longArrayOf(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">        ortEnv.use &#123; env -&gt;</span><br><span class="line">            <span class="keyword">val</span> tensor = OnnxTensor.createTensor(env, floatBuffer, shape)</span><br><span class="line">            <span class="keyword">val</span> output: OrtSession.Result? =</span><br><span class="line">                ortSession?.run(Collections.singletonMap(inputName, tensor))</span><br><span class="line">            <span class="keyword">val</span> resultBuffer = output?.<span class="keyword">get</span>(<span class="number">0</span>) <span class="keyword">as</span> OnnxTensor</span><br><span class="line">            <span class="keyword">return</span><span class="symbol">@withContext</span> (resultBuffer.floatBuffer)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></div>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul>
        <li><strong>Title:</strong> CLIP模型在Android端的应用</li>
        <li><strong>Author:</strong> Lulin</li>
        <li><strong>Created at
                :</strong> 2023-12-04 15:06:20</li>
        
            <li>
                <strong>Updated at
                    :</strong> 2024-05-13 03:49:29
            </li>
        
        <li>
            <strong>Link:</strong> https://blog.lllin.top/2023/12/04/clip-android/
        </li>
        <li>
            <strong>
                License:
            </strong>
            
            This work is licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0</a>.
            

        </li>
    </ul>
</div>

            </div>
        

        

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                        rel="prev"
                        href="/2023/12/04/chinese-clip/"
                        >
                            <span class="left arrow-icon flex justify-center items-center">
                                <i class="fa-solid fa-chevron-left"></i>
                            </span>
                            <span class="title flex justify-center items-center">
                                <span class="post-nav-title-item">ChineseClip</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                        rel="next"
                        href="/2023/10/31/clip/"
                        >
                            <span class="title flex justify-center items-center">
                                <span class="post-nav-title-item">CLIP模型在移动端的应用</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex justify-center items-center">
                                <i class="fa-solid fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        


        
            <div class="comment-container">
                <div class="comments-container pjax">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fa-solid fa-comments"></i>&nbsp;Comments
    </div>
    

        
            
 
    <div id="waline"></div>
    <script type="module"  data-swup-reload-script>
        import { init } from '/js/libs/waline.mjs';

        function loadWaline() {
            init({
                el: '#waline',
                serverURL: 'https://example.example.com',
                lang: 'zh-CN',
                dark: 'body[class~="dark-mode"]',
                requiredMeta: ['nick','mail'], // cannot customize by theme config, change it yourself
            });
        }

        if ('true') {
            const loadWalineTimeout = setTimeout(() => {
                loadWaline();
                clearTimeout(loadWalineTimeout);
            }, 1000);
        } else {
            window.addEventListener('DOMContentLoaded', loadWaline);
        }
        
    </script>



        
    
</div>

            </div>
        
    </div>

    
        <div class="toc-content-container">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <div class="toc-title">On this page</div>
        <div class="page-title">CLIP模型在Android端的应用</div>
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#CLIP-%E6%A8%A1%E5%9E%8B%E5%9C%A8-Android-%E7%AB%AF%E7%9A%84%E5%BA%94%E7%94%A8"><span class="nav-text">CLIP 模型在 Android 端的应用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#0-ONNXRuntime"><span class="nav-text">0. ONNXRuntime</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Google-MLKit-Translation-API"><span class="nav-text">1. Google MLKit Translation API</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Pytorch-%E8%BD%AC-ONNX"><span class="nav-text">3. Pytorch 转 ONNX</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-Android-%E8%B0%83%E7%94%A8-ONNX"><span class="nav-text">4. Android 调用 ONNX</span></a></li></ol></li></ol>

    </div>
</div>
        </div>
    
</div>



                

            </div>

            

        </div>

        <div class="main-content-footer">
            <footer class="footer mt-5 py-5 h-auto text-base text-third-text-color relative border-t-2 border-t-border-color">
    <div class="info-container py-3 text-center">
        
        <div class="text-center">
            &copy;
            
              <span>2020</span>
              -
            
            2024&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration: 0.5s; color: #f54545"></i>&nbsp;&nbsp;<a href="/">Lulin</a>
        </div>
        
            <script data-swup-reload-script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="relative text-center lg:absolute lg:right-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-right">
                
                    <span id="busuanzi_container_site_uv" class="lg:!block">
                        <span class="text-sm">VISITOR COUNT</span>
                        <span id="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="lg:!block">
                        <span class="text-sm">TOTAL PAGE VIEWS</span>
                        <span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="relative text-center lg:absolute lg:left-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-left">
            <span class="lg:block text-sm">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg class="relative top-[2px] inline-block align-baseline" version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" class="text-base" href="https://hexo.io">Hexo</a></span>
            <span class="text-sm lg:block">THEME&nbsp;<a class="text-base" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.5.0</a></span>
        </div>
        
            <div class="icp-info my-1"><a target="_blank" rel="nofollow" href="
                
                    https://beian.miit.gov.cn/
                
                ">鲁ICP备2024089611号-1</a></div>
        
        
            <div>
                Blog up for <span class="odometer" id="runtime_days" ></span> days <span class="odometer" id="runtime_hours"></span> hrs <span class="odometer" id="runtime_minutes"></span> Min <span class="odometer" id="runtime_seconds"></span> Sec
            </div>
        
        
            <script data-swup-reload-script>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
        
    </div>  
</footer>
        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="article-tools-list">
        <!-- TOC aside toggle -->
        
            <li class="right-bottom-tools page-aside-toggle">
                <i class="fa-regular fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fa-regular fa-comments"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-side-tools-container">
        <div class="side-tools-container">
    <ul class="hidden-tools-list">
        <li class="right-bottom-tools tool-font-adjust-plus flex justify-center items-center">
            <i class="fa-regular fa-magnifying-glass-plus"></i>
        </li>

        <li class="right-bottom-tools tool-font-adjust-minus flex justify-center items-center">
            <i class="fa-regular fa-magnifying-glass-minus"></i>
        </li>

        <li class="right-bottom-tools tool-dark-light-toggle flex justify-center items-center">
            <i class="fa-regular fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="right-bottom-tools tool-scroll-to-bottom flex justify-center items-center">
            <i class="fa-regular fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="visible-tools-list">
        <li class="right-bottom-tools toggle-tools-list flex justify-center items-center">
            <i class="fa-regular fa-cog fa-spin"></i>
        </li>
        
            <li class="right-bottom-tools tool-scroll-to-top flex justify-center items-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
        
    </ul>
</div>

    </div>

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fa-solid fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fa-solid fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fa-solid fa-spinner fa-spin-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>


    
<script src="/js/libs/Swup.min.js"></script>

<script src="/js/libs/SwupSlideTheme.min.js"></script>

<script src="/js/libs/SwupScriptsPlugin.min.js"></script>

<script src="/js/libs/SwupProgressPlugin.min.js"></script>

<script src="/js/libs/SwupScrollPlugin.min.js"></script>

<script src="/js/libs/SwupPreloadPlugin.min.js"></script>

<script>
    const swup = new Swup({
        plugins: [
            new SwupScriptsPlugin({
                optin: true,
            }),
            new SwupProgressPlugin(),
            new SwupScrollPlugin({
                offset: 80,
            }),
            new SwupSlideTheme({
                mainElement: ".main-content-body",
            }),
            new SwupPreloadPlugin(),
        ],
        containers: ["#swup"],
    });
</script>







<script src="/js/tools/imageViewer.js" type="module"></script>

<script src="/js/utils.js" type="module"></script>

<script src="/js/main.js" type="module"></script>

<script src="/js/layouts/navbarShrink.js" type="module"></script>

<script src="/js/tools/scrollTopBottom.js" type="module"></script>

<script src="/js/tools/lightDarkSwitch.js" type="module"></script>

<script src="/js/layouts/categoryList.js" type="module"></script>



    
<script src="/js/tools/localSearch.js" type="module"></script>




    
<script src="/js/tools/codeBlock.js" type="module"></script>




    
<script src="/js/layouts/lazyload.js" type="module"></script>




    
<script src="/js/tools/runtime.js"></script>

    
<script src="/js/libs/odometer.min.js"></script>

    
<link rel="stylesheet" href="/assets/odometer-theme-minimal.css">




  
<script src="/js/libs/Typed.min.js"></script>

  
<script src="/js/plugins/typed.js" type="module"></script>







<div class="post-scripts" data-swup-reload-script>
    
        
<script src="/js/libs/anime.min.js"></script>

        
<script src="/js/tools/tocToggle.js" type="module"></script>

<script src="/js/layouts/toc.js" type="module"></script>

<script src="/js/plugins/tabs.js" type="module"></script>

    
</div>


</body>
</html>
